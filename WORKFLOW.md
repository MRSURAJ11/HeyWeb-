# HeyWeb! Voice-First Workflow

This document explains the complete workflow of how HeyWeb! processes voice commands and executes actions.

## üéôÔ∏è Complete Workflow Overview

```
User Speaks ‚Üí Text ‚Üí AI Backend ‚Üí Action/Answer ‚Üí Spoken & Displayed Back
```

## üìã Detailed Step-by-Step Process

### 1. User Speaks a Command üéôÔ∏è
- **Trigger**: User says "HeyWeb" followed by their request
- **Technology**: Web Speech API (SpeechRecognition)
- **Example**: "HeyWeb, show me the latest news about AI"

### 2. Speech to Text üìù
- **Process**: Real-time voice-to-text conversion
- **Technology**: Browser's built-in speech recognition
- **Output**: "show me the latest news about AI"

### 3. Send to AI Backend üîó
- **Payload**: Text + conversation context + web page info
- **Technology**: HTTP POST to Node.js server
- **Data Structure**:
```json
{
  "messages": [
    {"role": "user", "content": "show me the latest news about AI"}
  ],
  "context": {
    "activeTab": {"url": "https://example.com"},
    "webAutomationEnabled": true,
    "currentTime": "2024-01-15T10:30:00Z",
    "userAgent": "Chrome/120.0.0.0"
  }
}
```

### 4. AI Processes the Request ü§ñ
- **Technology**: OpenAI GPT API
- **Process**:
  1. **Intent Recognition**: Understands user wants news about AI
  2. **Context Analysis**: Considers current page and conversation history
  3. **Action Planning**: Determines search action is needed
  4. **Response Generation**: Creates natural language response

### 5. Response Back to Frontend üì¶
- **Technology**: HTTP response with structured data
- **Data Structure**:
```json
{
  "assistant": "I'll search for the latest AI news for you.",
  "actions": [
    {
      "type": "search",
      "query": "latest artificial intelligence news",
      "engine": "google"
    }
  ]
}
```

### 6. Execute Actions ‚ö°
- **Frontend**: Processes action array
- **Actions**: 
  - **Search**: Opens Google search in new tab
  - **Web Automation**: Clicks buttons, fills forms, scrolls pages
  - **Navigation**: Opens websites, goes back/forward
  - **System**: Clears history, exports conversations

### 7. Text-to-Speech Reply üîä
- **Technology**: Web Speech Synthesis API
- **Process**: Converts AI response to spoken audio
- **Output**: "I'll search for the latest AI news for you."

### 8. Interactive UI Updates ‚ú®
- **Chat Bubbles**: Display conversation history
- **Waveform**: Visual audio feedback
- **Status Indicators**: Show processing state
- **Animations**: Smooth transitions and feedback

## üîÑ Real-World Example

### Scenario: User wants to check weather and log into a website

**Step 1: Voice Input**
```
User: "HeyWeb, what's the weather like today?"
```

**Step 2: Text Conversion**
```
Text: "what's the weather like today?"
```

**Step 3: AI Processing**
```json
{
  "assistant": "I'll search for current weather information for you.",
  "actions": [
    {
      "type": "search",
      "query": "current weather today",
      "engine": "google"
    }
  ]
}
```

**Step 4: Action Execution**
- Opens Google search for "current weather today"

**Step 5: Voice Response**
```
Spoken: "I'll search for current weather information for you."
```

**Step 6: UI Update**
- Adds conversation to chat history
- Shows processing animation
- Displays response bubble

---

**Step 1: Voice Input**
```
User: "HeyWeb, click the login button"
```

**Step 2: Text Conversion**
```
Text: "click the login button"
```

**Step 3: AI Processing**
```json
{
  "assistant": "I'll click the login button for you.",
  "actions": [
    {
      "type": "web_automation",
      "command": "click",
      "target": "login"
    }
  ]
}
```

**Step 4: Action Execution**
- Finds and clicks login button on current page

**Step 5: Voice Response**
```
Spoken: "I'll click the login button for you."
```

## üõ†Ô∏è Technical Implementation

### Frontend (React)
```javascript
// 1. Voice Recognition
const recognition = new SpeechRecognition();
recognition.onresult = (event) => {
  const text = event.results[0][0].transcript;
  handleUserCommand(text);
};

// 2. Send to Backend
const response = await axios.post('/api/chat', {
  messages: [...messages, { role: 'user', content: text }],
  context: { activeTab, webAutomationEnabled }
});

// 3. Execute Actions
if (response.data.actions) {
  await executeActions(response.data.actions);
}

// 4. Text-to-Speech
speakText(response.data.assistant);
```

### Backend (Node.js)
```javascript
// 1. Process with OpenAI
const aiResponse = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [systemMessage, ...userMessages],
  temperature: 0.7
});

// 2. Parse Actions
const actions = parseActionsFromResponse(aiResponse.content);

// 3. Return Response
res.json({
  assistant: aiResponse.content,
  actions: actions
});
```

## üéØ Action Types

### 1. Web Automation
```javascript
{
  type: "web_automation",
  command: "click|type|scroll|navigate",
  target: "element_name",
  value: "text_to_type",
  direction: "up|down"
}
```

### 2. Search
```javascript
{
  type: "search",
  query: "search_term",
  engine: "google|bing|youtube|wikipedia"
}
```

### 3. Navigation
```javascript
{
  type: "navigation",
  url: "https://example.com",
  target: "_blank|_self"
}
```

### 4. System
```javascript
{
  type: "system",
  command: "clear_history|export_conversation|open_settings"
}
```

## üîç Context Awareness

The AI considers multiple context factors:

1. **Conversation History**: Previous messages and actions
2. **Current Web Page**: URL, title, available elements
3. **Time Context**: Current time and date
4. **User Agent**: Browser and device information
5. **Web Automation Status**: Whether automation is active

## üöÄ Performance Optimizations

1. **Real-time Processing**: Voice recognition happens as user speaks
2. **Context Caching**: Previous context is reused when relevant
3. **Action Batching**: Multiple actions can be executed together
4. **Error Handling**: Graceful degradation for unsupported actions
5. **Response Streaming**: AI responses are processed incrementally

## üîí Security Considerations

1. **Input Sanitization**: All user input is validated
2. **Action Validation**: Actions are verified before execution
3. **Permission Scoping**: Web automation only affects active tab
4. **Rate Limiting**: API calls are limited to prevent abuse
5. **Error Logging**: Failed actions are logged for debugging

---

**HeyWeb!** - Making voice interaction with the web as natural as conversation! üé§‚ú®
